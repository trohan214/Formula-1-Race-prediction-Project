{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "358cd2f5-ae82-4c0f-a171-da5f199fcc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastf1 in /opt/anaconda3/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.5.1)\n",
      "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.12/site-packages (5.24.1)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.12/site-packages (from fastf1) (2.9.0.post0)\n",
      "Requirement already satisfied: rapidfuzz in /opt/anaconda3/lib/python3.12/site-packages (from fastf1) (3.13.0)\n",
      "Requirement already satisfied: requests-cache>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from fastf1) (1.2.1)\n",
      "Requirement already satisfied: requests>=2.28.1 in /opt/anaconda3/lib/python3.12/site-packages (from fastf1) (2.32.3)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.8.1 in /opt/anaconda3/lib/python3.12/site-packages (from fastf1) (1.13.1)\n",
      "Requirement already satisfied: timple>=0.1.6 in /opt/anaconda3/lib/python3.12/site-packages (from fastf1) (0.1.8)\n",
      "Requirement already satisfied: websockets<14,>=10.3 in /opt/anaconda3/lib/python3.12/site-packages (from fastf1) (13.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil->fastf1) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.28.1->fastf1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.28.1->fastf1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.28.1->fastf1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.28.1->fastf1) (2024.12.14)\n",
      "Requirement already satisfied: attrs>=21.2 in /opt/anaconda3/lib/python3.12/site-packages (from requests-cache>=1.0.0->fastf1) (25.3.0)\n",
      "Requirement already satisfied: cattrs>=22.2 in /opt/anaconda3/lib/python3.12/site-packages (from requests-cache>=1.0.0->fastf1) (25.1.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests-cache>=1.0.0->fastf1) (3.10.0)\n",
      "Requirement already satisfied: url-normalize>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from requests-cache>=1.0.0->fastf1) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/anaconda3/lib/python3.12/site-packages (from cattrs>=22.2->requests-cache>=1.0.0->fastf1) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fastf1 pandas numpy matplotlib seaborn scikit-learn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3c87420e-f9a9-48a6-be1a-fcc3e7f858c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLANATION:\n",
    "# This cell installs necessary packages and imports them\n",
    "# - fastf1: Official F1 API for real-time and historical data\n",
    "# - pandas: Data manipulation and analysis\n",
    "# - numpy: Numerical computing\n",
    "# - matplotlib/seaborn: Data visualization\n",
    "# - scikit-learn: Machine learning algorithms\n",
    "\n",
    "\n",
    "\n",
    "import fastf1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Added imports for our machine learning workflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "fastf1.Cache.enable_cache('f1_cache') # This caches data locally to avoid repeated downloads\n",
    "\n",
    "# Let's also add a function to safely copy and show dataset changes\n",
    "def show_dataframe_info(df, title=\"Dataset Info\"):\n",
    "    \"\"\"Helper function to display dataset information\"\"\"\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Memory usage: {df.memory_usage().sum() / 1024**2:.2f} MB\")\n",
    "    return df\n",
    "\n",
    "def safe_copy_and_modify(original_df, title=\"Dataset Copy\"):\n",
    "    \"\"\"Create a safe copy of dataframe and show info\"\"\"\n",
    "    df_copy = original_df.copy()\n",
    "    print(f\"\\nüîÑ Created copy: {title}\")\n",
    "    show_dataframe_info(df_copy, f\"Copy - {title}\")\n",
    "    return df_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "92d64b90-ba05-4d16-8ccd-3f7b74ef273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLANATION:\n",
    "# This function converts various time formats (lap times, qualifying times) \n",
    "# into seconds for easier numerical analysis\n",
    "# F1 timing data comes in different formats, this standardizes them\n",
    "\n",
    "def to_seconds(x):\n",
    "    \"\"\"Convert laptime / timedelta / string to seconds.\"\"\"\n",
    "    try:\n",
    "        return pd.to_timedelta(x).total_seconds()\n",
    "    except Exception:\n",
    "        try:\n",
    "            return float(x)\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "\n",
    "# Let's add some more utility functions for data exploration\n",
    "def explore_column(df, column_name):\n",
    "    \"\"\"Explore a specific column in detail\"\"\"\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"‚ùå Column '{column_name}' not found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüîç Exploring column: '{column_name}'\")\n",
    "    print(f\"Data type: {df[column_name].dtype}\")\n",
    "    print(f\"Non-null count: {df[column_name].count()}/{len(df)}\")\n",
    "    print(f\"Unique values: {df[column_name].nunique()}\")\n",
    "    \n",
    "    if df[column_name].dtype in ['object']:\n",
    "        print(f\"Sample values: {df[column_name].unique()[:10]}\")\n",
    "    else:\n",
    "        print(f\"Min: {df[column_name].min()}, Max: {df[column_name].max()}\")\n",
    "        print(f\"Mean: {df[column_name].mean():.2f}\")\n",
    "\n",
    "def compare_datasets(original, modified, title=\"Comparison\"):\n",
    "    \"\"\"Compare two datasets and show differences\"\"\"\n",
    "    print(f\"\\nüìä {title}\")\n",
    "    print(f\"Original shape: {original.shape}\")\n",
    "    print(f\"Modified shape: {modified.shape}\")\n",
    "    print(f\"Columns removed: {set(original.columns) - set(modified.columns)}\")\n",
    "    print(f\"Columns added: {set(modified.columns) - set(original.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "406fda69-e8d0-4f8b-bc7b-14dc709efc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# 3. Load race + qualifying session\n",
    "# ===============================================================\n",
    "\n",
    "def load_race_and_qual(year, gp_name):\n",
    "    # Load race session\n",
    "    race = fastf1.get_session(year, gp_name, 'R')\n",
    "    race.load()\n",
    "\n",
    "    rr = race.results.copy().reset_index(drop=True).rename(columns={\n",
    "        'TeamName': 'Team',\n",
    "        'GridPosition': 'Grid',\n",
    "        'ClassifiedPosition': 'Position',\n",
    "        'Number': 'DriverNumber'\n",
    "    })\n",
    "\n",
    "    # Try to extract race date safely\n",
    "    race_date = pd.NaT\n",
    "    for cand in (\n",
    "        getattr(race, 'date', None),\n",
    "        getattr(race, 'start_time', None),\n",
    "        getattr(getattr(race, 'event', {}), 'EventDate', None),\n",
    "        isinstance(getattr(race, 'event', None), dict) and race.event.get('EventDate')\n",
    "    ):\n",
    "        if cand is not None:\n",
    "            race_date = pd.to_datetime(cand)\n",
    "            break\n",
    "\n",
    "    meta = {\n",
    "        'RaceDate': race_date,\n",
    "        'Event': getattr(getattr(race, 'event', {}), 'EventName', None) or gp_name,\n",
    "        'Season': year\n",
    "    }\n",
    "\n",
    "    # Try qualifying\n",
    "    qr = None\n",
    "    try:\n",
    "        qual = fastf1.get_session(year, gp_name, 'Q')\n",
    "        qual.load()\n",
    "        qr = qual.results.copy().reset_index(drop=True).rename(columns={\n",
    "            'TeamName': 'Team',\n",
    "            'ClassifiedPosition': 'QualPos',\n",
    "            'GridPosition': 'QualGrid'\n",
    "        })\n",
    "        qr['QualTime_sec'] = qr['Q3'].apply(to_seconds)\n",
    "    except Exception:\n",
    "        # For sprint weekends, try SQ\n",
    "        try:\n",
    "            qual = fastf1.get_session(year, gp_name, 'SQ')\n",
    "            qual.load()\n",
    "            qr = qual.results.copy().reset_index(drop=True).rename(columns={\n",
    "                'TeamName': 'Team',\n",
    "                'ClassifiedPosition': 'QualPos',\n",
    "                'GridPosition': 'QualGrid'\n",
    "            })\n",
    "            qr['QualTime_sec'] = qr['Q3'].apply(to_seconds)\n",
    "        except Exception:\n",
    "            qr = None\n",
    "\n",
    "    return rr, qr, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f556f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "def assemble_prerace_features(rr, qr, meta, prior_results):\n",
    "    df = rr.copy()\n",
    "    df['RaceDate'] = meta['RaceDate']\n",
    "    df['Event'] = meta['Event']\n",
    "    df['Season'] = meta['Season']\n",
    "\n",
    "    # Pick identifier (Driver Abbreviation or Number)\n",
    "    if 'Abbreviation' in df.columns:\n",
    "        driver_id_col = 'Abbreviation'\n",
    "    elif 'DriverNumber' in df.columns:\n",
    "        driver_id_col = 'DriverNumber'\n",
    "    else:\n",
    "        raise KeyError(\"No suitable driver identifier found (expected Abbreviation or DriverNumber).\")\n",
    "\n",
    "    # --- Clean Position column ---\n",
    "    def clean_position(pos):\n",
    "        try:\n",
    "            return int(pos)\n",
    "        except Exception:\n",
    "            return 99   # e.g. DNF, NC, DSQ -> treat as poor finish\n",
    "    df['Position'] = df['Position'].apply(clean_position)\n",
    "\n",
    "    if not prior_results.empty and 'Position' in prior_results.columns:\n",
    "        prior_results = prior_results.copy()\n",
    "        prior_results['Position'] = prior_results['Position'].apply(clean_position)\n",
    "\n",
    "    # --- Attach Qualifying grid ---\n",
    "    if qr is not None and driver_id_col in qr.columns:\n",
    "        qual_map = qr.set_index(driver_id_col)['QualGrid'].to_dict()\n",
    "        df['QualGrid'] = df[driver_id_col].map(qual_map)\n",
    "    else:\n",
    "        df['QualGrid'] = df['Grid']\n",
    "\n",
    "    # --- Constructor form (points up to now) ---\n",
    "    team_points = (\n",
    "        prior_results.groupby('Team')['Points'].sum()\n",
    "        if not prior_results.empty else pd.Series(dtype=float)\n",
    "    )\n",
    "    df['ConstructorPointsSoFar'] = df['Team'].map(team_points).fillna(0)\n",
    "\n",
    "    # --- Driver form (avg last 3 results) ---\n",
    "    if not prior_results.empty and driver_id_col in prior_results.columns:\n",
    "        driver_form = (\n",
    "            prior_results.groupby(driver_id_col)['Position']\n",
    "            .apply(lambda x: x.tail(3).mean())\n",
    "        )\n",
    "        df['DriverForm'] = df[driver_id_col].map(driver_form).fillna(10)\n",
    "    else:\n",
    "        df['DriverForm'] = 10\n",
    "\n",
    "    # --- Ensure scalars are numeric ---\n",
    "    df['Grid'] = pd.to_numeric(df['Grid'], errors='coerce')\n",
    "    df['QualGrid'] = pd.to_numeric(df['QualGrid'], errors='coerce')\n",
    "    df['ConstructorPointsSoFar'] = pd.to_numeric(df['ConstructorPointsSoFar'], errors='coerce')\n",
    "    df['DriverForm'] = pd.to_numeric(df['DriverForm'], errors='coerce')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cf70d434-69e3-48f1-a28e-ff1f409ce9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "def build_prerace_dataset(event_list):\n",
    "    \"\"\"\n",
    "    Build pre-race dataset across multiple events.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    event_list : list of tuples\n",
    "        Example: [(2023, \"Bahrain Grand Prix\"), (2023, \"Saudi Arabian Grand Prix\"), ...]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Features DataFrame with cleaned, standardized columns.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    prior_results = pd.DataFrame()\n",
    "\n",
    "    for season, event in event_list:\n",
    "        try:\n",
    "            # Load event\n",
    "            race = fastf1.get_event(season, event)\n",
    "            race.load()\n",
    "\n",
    "            # Race results\n",
    "            rr = race.results.copy().reset_index(drop=True)\n",
    "\n",
    "            # Qualifying results\n",
    "            try:\n",
    "                qual = race.get_qualifying()\n",
    "                qr = qual[['Abbreviation', 'Grid']].copy()\n",
    "                qr.rename(columns={'Grid': 'QualGrid'}, inplace=True)\n",
    "            except Exception:\n",
    "                qr = None\n",
    "\n",
    "            # Metadata\n",
    "            meta = {\n",
    "                'Season': season,\n",
    "                'Event': event,\n",
    "                'RaceDate': race.date,\n",
    "            }\n",
    "\n",
    "            # Build features for this race\n",
    "            features = assemble_prerace_features(rr, qr, meta, prior_results)\n",
    "\n",
    "            all_features.append(features)\n",
    "\n",
    "            # Update prior_results with cleaned data\n",
    "            prior_results = pd.concat([prior_results, features], ignore_index=True)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {event} {season} due to error: {e}\")\n",
    "\n",
    "    if not all_features:\n",
    "        raise ValueError(\"No features could be built. Check event list or data availability.\")\n",
    "\n",
    "    return pd.concat(all_features, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9dbd27ce-2ba3-40d4-ba3e-a80785d40497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Bahrain Grand Prix 2023 due to error: 'Event' object has no attribute 'load'\n",
      "Skipping Saudi Arabian Grand Prix 2023 due to error: 'Event' object has no attribute 'load'\n",
      "Skipping Australian Grand Prix 2023 due to error: 'Event' object has no attribute 'load'\n",
      "Skipping Azerbaijan Grand Prix 2023 due to error: 'Event' object has no attribute 'load'\n",
      "Skipping Miami Grand Prix 2023 due to error: 'Event' object has no attribute 'load'\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No features could be built. Check event list or data availability.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ===============================================================\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 6. Example: build dataset for a few races\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ===============================================================\u001b[39;00m\n\u001b[1;32m      5\u001b[0m event_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     (\u001b[38;5;241m2023\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBahrain Grand Prix\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      7\u001b[0m     (\u001b[38;5;241m2023\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaudi Arabian Grand Prix\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     (\u001b[38;5;241m2023\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMiami Grand Prix\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     11\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m features_df \u001b[38;5;241m=\u001b[39m build_prerace_dataset(event_list)\n\u001b[1;32m     14\u001b[0m features_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn[75], line 54\u001b[0m, in \u001b[0;36mbuild_prerace_dataset\u001b[0;34m(event_list)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m due to error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_features:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo features could be built. Check event list or data availability.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mconcat(all_features, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: No features could be built. Check event list or data availability."
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# 6. Example: build dataset for a few races\n",
    "# ===============================================================\n",
    "\n",
    "event_list = [\n",
    "    (2023, \"Bahrain Grand Prix\"),\n",
    "    (2023, \"Saudi Arabian Grand Prix\"),\n",
    "    (2023, \"Australian Grand Prix\"),\n",
    "    (2023, \"Azerbaijan Grand Prix\"),\n",
    "    (2023, \"Miami Grand Prix\"),\n",
    "]\n",
    "\n",
    "features_df = build_prerace_dataset(event_list)\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5730e1af-7a58-4e51-af02-52e0c2402d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
